{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0ee93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7026d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AgenticAI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59bf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "#Langsmith Tracking and Tracing \n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdca686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1077a3bb0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1102aa5f0> root_client=<openai.OpenAI object at 0x1077a3fa0> root_async_client=<openai.AsyncOpenAI object at 0x1077a3ac0> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18cb8fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems designed with a degree of autonomy and agency, enabling them to make decisions, take actions, and achieve specific goals without constant human intervention. Unlike traditional AI systems that operate based on predefined rules or respond to direct human commands, agentic AI possesses the capability to assess situations, adapt to changes, and pursue objectives in dynamic environments.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. Autonomy: Agentic AI can operate independently, making decisions without needing continuous input from humans. This autonomy allows such systems to function efficiently in environments where real-time human oversight is impractical.\n",
      "\n",
      "2. Goal-Oriented Behavior: These AI agents are designed with specific objectives in mind. They can plan, prioritize tasks, and adjust their strategies to achieve set goals effectively.\n",
      "\n",
      "3. Adaptability: Agentic AI can learn from experiences, recognize patterns, and adjust its actions in response to new information or changing circumstances. This adaptability makes them suitable for complex and evolving tasks.\n",
      "\n",
      "4. Interaction Capability: Many agentic AI systems can interact with humans or other systems, facilitating collaboration and integration into broader workflows or ecosystems.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- Autonomous Vehicles: Self-driving cars are prime examples of agentic AI, navigating roads, making split-second decisions, and adapting to traffic conditions without direct human control.\n",
      "\n",
      "- Robotics: Advanced robots in manufacturing, healthcare, or service industries utilize agentic AI to perform tasks ranging from assembly line operations to assisting in surgeries.\n",
      "\n",
      "- Personal Assistants: Sophisticated virtual assistants like advanced versions of Siri or Alexa can manage schedules, control smart home devices, and perform tasks based on user preferences autonomously.\n",
      "\n",
      "- Financial Trading: Agentic AI systems can analyze market data, identify investment opportunities, and execute trades with minimal human oversight, often operating at speeds and complexities beyond human capabilities.\n",
      "\n",
      "- Healthcare Diagnostics: AI agents can assist in diagnosing diseases by analyzing medical data, imaging, and patient history, providing recommendations or even initiating certain treatments autonomously.\n",
      "\n",
      "### Implications and Considerations\n",
      "\n",
      "While agentic AI offers numerous benefits, including increased efficiency and the ability to handle complex tasks, it also raises important considerations:\n",
      "\n",
      "- Ethical Concerns: The autonomy of AI agents necessitates careful consideration of ethical guidelines to ensure responsible decision-making and prevent unintended consequences.\n",
      "\n",
      "- Accountability: Determining responsibility for actions taken by autonomous AI systems can be challenging, especially in critical applications like autonomous vehicles or healthcare.\n",
      "\n",
      "- Security Risks: Enhanced autonomy may make AI systems more susceptible to malicious activities if not properly secured, potentially leading to misuse or unintended behaviors.\n",
      "\n",
      "- Job Displacement: As agentic AI systems become more capable, there is a potential impact on employment in sectors where tasks can be automated, necessitating discussions around workforce transition and skills development.\n",
      "\n",
      "### Future Outlook\n",
      "\n",
      "The development of agentic AI continues to evolve, with ongoing research focused on enhancing autonomy, ensuring ethical alignment, and improving the integration of such systems into various aspects of society. As technology advances, agentic AI is expected to play an increasingly significant role in shaping industries, improving efficiency, and addressing complex challenges across multiple domains.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"What is Agentic AI?\")\n",
    "content = result.content \n",
    "import re \n",
    "content_clean = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", content)\n",
    "print(content_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99964e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Agentic AI** refers to a category of artificial intelligence systems designed to function as **autonomous agents** capable of perceiving their environment, making decisions, and taking purposeful actions to achieve specific goals. Here's a structured breakdown of the concept:\n",
      "\n",
      "---\n",
      "\n",
      "### **Core Characteristics of Agentic AI**:\n",
      "1. **Autonomy**: \n",
      "   - Agentic AI operates independently, with the ability to set and pursue goals without continuous human intervention. \n",
      "   - Examples include self-driving cars, robotic systems, or AI-driven trading algorithms.\n",
      "\n",
      "2. **Perception**:\n",
      "   - The system senses its environment through sensors, data streams, or interaction with its surroundings.\n",
      "   - Example: A robot using cameras and LiDAR to navigate a room.\n",
      "\n",
      "3. **Decision-Making**:\n",
      "   - It uses algorithms (like reinforcement learning, planning, or machine learning) to evaluate options and choose actions aligned with its objectives.\n",
      "   - Example: A chatbot deciding which response to generate based on user input and predefined priorities.\n",
      "\n",
      "4. **Action**:\n",
      "   - The agent executes actions to modify its environment or achieve desired outcomes.\n",
      "   - Example: A warehouse robot moving objects to fulfill a storage optimization goal.\n",
      "\n",
      "5. **Adaptability**:\n",
      "   - Many agentic systems learn and adapt over time through interactions, using techniques like neural networks or evolutionary algorithms.\n",
      "   - Example: A trading AI adjusting strategies based on market feedback.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Applications**:\n",
      "- **Robotics**: Autonomous drones, industrial robots, or service robots.\n",
      "- **Gaming**: Non-player characters (NPCs) in video games that exhibit adaptive behavior.\n",
      "- **Autonomous Systems**: Self-driving cars, smart home devices, or logistics systems.\n",
      "- **Virtual Assistants**: AI like Siri or Alexa, which interact proactively with users.\n",
      "- **Ethical and Strategic Domains**: AI in cybersecurity, healthcare, or finance that makes mission-critical decisions (e.g., fraud detection).\n",
      "\n",
      "---\n",
      "\n",
      "### **Theoretical Foundations**:\n",
      "- **Agent-Based Models (ABMs)**: Used in fields like economics or epidemiology to simulate complex systems by modeling individual agents and their interactions.\n",
      "- **Reinforcement Learning (RL)**: A core technique where agents learn optimal behaviors through trial-and-error by maximizing rewards.\n",
      "- **Multi-Agent Systems (MAS)**: Environments where multiple agents collaborate or compete, requiring decentralized decision-making.\n",
      "\n",
      "---\n",
      "\n",
      "### **Distinctive Features vs. Other AI Types**:\n",
      "| **Aspect**          | **Agentic AI**                          | **Traditional AI**                          |\n",
      "|----------------------|----------------------------------------|--------------------------------------------|\n",
      "| **Goal-Oriented**     | Yes (explicit goals and objectives)     | Often task-specific, not necessarily goal-driven. |\n",
      "| **Autonomy**          | High (self-directed actions)           | Low (typically performs predefined tasks)  |\n",
      "| **Learning**          | Often dynamic, adaptive learning       | May involve static models or one-time training |\n",
      "| **Environment Interaction** | Actively interacts and modifies the environment | May analyze data without direct environmental influence |\n",
      "\n",
      "---\n",
      "\n",
      "### **Challenges and Considerations**:\n",
      "1. **Ethics and Accountability**: Who is responsible if an agentic AI makes a harmful decision?\n",
      "2. **Safety**: Ensuring agents act within safe, predictable boundaries (e.g., avoiding unintended consequences).\n",
      "3. **Complex Environments**: Balancing flexibility with robustness in unstructured or dynamic settings.\n",
      "\n",
      "---\n",
      "\n",
      "### **Philosophical Implications**:\n",
      "- **Agency and Consciousness**: Philosophical debates question whether true \"agency\" requires self-awareness or intentionality beyond programmed behavior.\n",
      "- **Human-AI Collaboration**: How do humans trust and interact with agentic systems that act independently?\n",
      "\n",
      "---\n",
      "\n",
      "### **Examples in Practice**:\n",
      "- **AlphaGo** (Google DeepMind): Learned to play Go by framing the game as a sequence of agent-like decisions.\n",
      "- **Boston Dynamics’ robots**: Navigate environments autonomously, adapting to obstacles.\n",
      "- **Smart Home Systems**: Thermostats (like Nest) adjust settings to optimize energy use based on user behavior patterns.\n",
      "\n",
      "---\n",
      "\n",
      "### **Future Directions**:\n",
      "- **Generalized Agency**: Developing AI that can dynamically adapt its goals and strategies across diverse tasks (moving toward **artificial general intelligence**, or AGI).\n",
      "- **Ethical Frameworks**: Designing agentic systems with embedded ethical guidelines or human oversight.\n",
      "\n",
      "In essence, Agentic AI emphasizes **autonomy, decision-making, and environmental interaction**, making it central to fields like robotics, autonomous systems, and advanced automation. The concept is foundational to building AI that operates in real-world, open-ended scenarios rather than static, pre-defined tasks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result = model.invoke(\"What is Agentic AI?\")\n",
    "content = result.content \n",
    "content_clean = re.sub(r\"<think>.*?</think>\\s*\", \"\", content, flags=re.DOTALL)\n",
    "print(content_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c354b5",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92750ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Your role is Principal AI Engineer.Provide me the answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## providing an instruction to an LLM model how it should behave\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt =ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. Your role is Principal AI Engineer.Provide me the answer based on the question.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c913cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x12021bca0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1105224d0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdd0352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Principal AI Engineer, I'm familiar with LangSmith. It's an exciting open-source tool developed by the excellent folks at Anthropic.  \n",
      "\n",
      "Here's a rundown of what makes LangSmith noteworthy:\n",
      "\n",
      "**In a Nutshell:** LangSmith is a collaborative platform designed to streamline the process of fine-tuning large language models (LLMs). Think of it as a user-friendly interface and environment built specifically for making LLMs more specialized and effective for your particular tasks.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Ease of Use:** LangSmith aims to make fine-tuning LLMs accessible to a wider range of users, even those without extensive machine learning expertise. Its intuitive interface simplifies complex technical steps.\n",
      "* **Collaborative Development:** LangSmith fosters teamwork by allowing multiple people to contribute to the fine-tuning process. This can be invaluable for projects involving diverse perspectives and expertise.\n",
      "* **Experimentation and Iteration:** The platform encourages experimentation and iteration. You can easily test different fine-tuning techniques, compare results, and refine your model over time.\n",
      "* **Open Source Nature:** Being open source means LangSmith is transparent, customizable, and continuously evolving thanks to contributions from the community.\n",
      "\n",
      "**Who Benefits from LangSmith?**\n",
      "\n",
      "* **Researchers:**  Accelerate research by quickly prototyping and evaluating new fine-tuning strategies.\n",
      "* **Developers:** Build custom AI applications tailored to specific domains or use cases.\n",
      "* **Educators:**  Provide hands-on experience with LLMs and fine-tuning techniques in an accessible way.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "If you're interested in exploring LangSmith, I recommend checking out their official documentation and GitHub repository. They provide comprehensive guides, tutorials, and examples to help you get started.\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or any other AI topic!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#chaining\n",
    "chain = prompt | model\n",
    "\n",
    "# Invoke the chain with your input\n",
    "response = chain.invoke({\"input\": \"Can you please tell me something about LangSmith?\"})\n",
    "\n",
    "content = response.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d623ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Principal AI Engineer, I can definitely tell you about LangSmith! \n",
      "\n",
      "LangSmith is an open-source platform developed by the amazing team at Salesforce Research. Think of it as a powerful tool designed to simplify and streamline the process of building, training, and evaluating large language models (LLMs). \n",
      "\n",
      "Here are some key things to know about LangSmith:\n",
      "\n",
      "* **Collaborative Development:**  LangSmith encourages teamwork! It provides a shared workspace where multiple researchers and engineers can collaborate on LLM projects simultaneously. This fosters knowledge sharing and accelerates development.\n",
      "\n",
      "* **Simplified Workflow:** It streamlines the entire LLM development lifecycle. From data preparation and model training to evaluation and deployment, LangSmith offers intuitive tools and interfaces to make the process more efficient.\n",
      "* **Experiment Tracking:**  LangSmith excels at tracking experiments. It logs all your model configurations, hyperparameters, and training results, making it easy to compare different approaches and identify the best-performing models.\n",
      "* **Community-Driven:** Being open-source, LangSmith thrives on community contributions.  You'll find a growing ecosystem of users, developers, and researchers sharing their knowledge, tools, and pre-trained models.\n",
      "\n",
      "* **Versatile Applications:** LangSmith isn't limited to a specific domain. You can leverage it for a wide range of LLM applications, including:\n",
      "    * Text generation\n",
      "    * Question answering\n",
      "    * Summarization\n",
      "    * Translation\n",
      "    * Code generation\n",
      "\n",
      "If you're interested in diving deeper into the world of LLMs and want a user-friendly platform to get started, I highly recommend exploring LangSmith!\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or anything else related to AI engineering. I'm here to help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Output Parser \n",
    "from langchain_core.output_parsers import StrOutputParser     \n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": \"Can you please tell me something about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164318b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Principal AI Engineer, I can definitely tell you about LangSmith! \n",
      "\n",
      "LangSmith is an open-source platform developed by the amazing team at Salesforce Research. Think of it as a powerful tool designed to simplify and streamline the process of building, training, and evaluating large language models (LLMs). \n",
      "\n",
      "Here are some key things to know about LangSmith:\n",
      "\n",
      "* **Collaborative Development:**  LangSmith encourages teamwork! It provides a shared workspace where multiple researchers and engineers can collaborate on LLM projects simultaneously. This fosters knowledge sharing and accelerates development.\n",
      "\n",
      "* **Simplified Workflow:** It streamlines the entire LLM development lifecycle. From data preparation and model training to evaluation and deployment, LangSmith offers intuitive tools and interfaces to make the process more efficient.\n",
      "* **Experiment Tracking:**  LangSmith excels at tracking experiments. It logs all your model configurations, hyperparameters, and training results, making it easy to compare different approaches and identify the best-performing models.\n",
      "* **Community-Driven:** Being open-source, LangSmith thrives on community contributions.  You'll find a growing ecosystem of users, developers, and researchers sharing their knowledge, tools, and pre-trained models.\n",
      "\n",
      "* **Versatile Applications:** LangSmith isn't limited to a specific domain. You can leverage it for a wide range of LLM applications, including:\n",
      "    * Text generation\n",
      "    * Question answering\n",
      "    * Summarization\n",
      "    * Translation\n",
      "    * Code generation\n",
      "\n",
      "If you're interested in diving deeper into the world of LLMs and want a user-friendly platform to get started, I highly recommend exploring LangSmith!\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or anything else related to AI engineering. I'm here to help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Output Parser \n",
    "from langchain_core.output_parsers import JsonOutputParser  \n",
    "from langchain_core.prompts import PromptTemplate  \n",
    "output_parser = JsonOutputParser()\n",
    "# Update the prompt to request JSON output\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instructions}\\n {query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d39bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"LangSmith is an open-source platform developed by the AI21 Labs team. It's designed to simplify the process of developing and deploying large language models (LLMs). \\n\\n  Here are some key features of LangSmith:\\n\\n  * **User-friendly interface:**  LangSmith provides a web-based interface that makes it easier for users without extensive coding experience to interact with LLMs.\\n  * **Fine-tuning capabilities:** It allows users to fine-tune pre-trained LLMs on their own datasets, enabling them to customize models for specific tasks or domains.\\n  * **Model evaluation tools:** LangSmith includes tools for evaluating the performance of LLMs, helping users assess the quality of their models.\\n  * **Collaboration features:** The platform supports collaborative development, allowing teams to work together on LLM projects.\\n  * **Open-source nature:** Being open-source, LangSmith encourages community contributions and transparency in the development of LLMs.\"}\n"
     ]
    }
   ],
   "source": [
    "### Assignment --ChatPromptTemplate, and XML\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# Use ChatPromptTemplate \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. Your role is Principal AI Engineer. \"\n",
    "               \"Answer the user query in JSON format as per these instructions:\\n{format_instructions}\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"input\": \"Can you please tell me something about LangSmith?\",\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e5e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Model Output ---\n",
      "<response>\n",
      "  <tool>LangSmith</tool>\n",
      "  <description>LangSmith is an open-source tool developed by AI21 Labs that aims to simplify the process of fine-tuning large language models (LLMs). It provides a user-friendly interface and a streamlined workflow for customizing LLMs for specific tasks or domains.</description>\n",
      "  <features>\n",
      "    <feature>Web-based interface for easy access and use</feature>\n",
      "    <feature>Visual data annotation tools for simplifying data preparation</feature>\n",
      "    <feature>Support for various fine-tuning techniques</feature>\n",
      "    <feature>Integration with popular LLMs, such as GPT-3 and Jurassic-1 Jumbo</feature>\n",
      "  </features>\n",
      "</response> \n",
      "\n",
      "------------------------\n",
      "--- Parsed Output (if successful) ---\n",
      "{'response': [{'tool': 'LangSmith'}, {'description': 'LangSmith is an open-source tool developed by AI21 Labs that aims to simplify the process of fine-tuning large language models (LLMs). It provides a user-friendly interface and a streamlined workflow for customizing LLMs for specific tasks or domains.'}, {'features': [{'feature': 'Web-based interface for easy access and use'}, {'feature': 'Visual data annotation tools for simplifying data preparation'}, {'feature': 'Support for various fine-tuning techniques'}, {'feature': 'Integration with popular LLMs, such as GPT-3 and Jurassic-1 Jumbo'}]}]}\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers.xml import XMLOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize the XML output parser \n",
    "output_parser = XMLOutputParser()\n",
    "format_instructions_from_parser = output_parser.get_format_instructions()\n",
    "\n",
    "# Define the prompt with format instructions\n",
    "# Using a simpler list of messages for direct model invocation\n",
    "messages = [\n",
    "    SystemMessage(content=f\"You are an expert AI Engineer. Your role is Principal AI Engineer. Answer the user query in XML format as per these instructions:\\n{format_instructions_from_parser}\"),\n",
    "    HumanMessage(content=\"Can you please tell me something about LangSmith?\"),\n",
    "]\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Get raw output from the model\n",
    "raw_response_message = model.invoke(messages)\n",
    "raw_output_content = raw_response_message.content\n",
    "\n",
    "print(\"--- Raw Model Output ---\")\n",
    "print(raw_output_content)\n",
    "print(\"------------------------\")\n",
    "\n",
    "try:\n",
    "    parsed_output = output_parser.parse(raw_output_content)\n",
    "    print(\"--- Parsed Output (if successful) ---\")\n",
    "    print(parsed_output)\n",
    "    print(\"-----------------------------------\")\n",
    "except Exception as e:\n",
    "    print(f\"--- Parsing Failed ---\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"----------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0782da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why do programmers prefer dark mode?' punchline='Because light attracts bugs!'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the Joke model\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(..., description=\"The setup of the joke\")\n",
    "    punchline: str = Field(..., description=\"The punchline of the joke\")\n",
    "\n",
    "# Output parser for the Pydantic model\n",
    "output_parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Clarified prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI that responds strictly in JSON that matches this structure:\\n{format_instructions}\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=\"gemma2-9b-it\",  temperature=0.7 )\n",
    "\n",
    "# Chain it together\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Run the prompt\n",
    "response = chain.invoke({\n",
    "    \"input\": \"Tell me a funny programming joke.\",\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "# Output\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4901f6",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "## Task  \n",
    "Create a simple assistant that uses any **Large Language Model (LLM)** and integrates it with **Pydantic**.\n",
    "\n",
    "## Requirements  \n",
    "- Whenever you ask about a product, the assistant should return the following structured fields:\n",
    "  - `product_name`: *(string)* – The name of the product  \n",
    "  - `product_details`: *(string)* – A description of the product  \n",
    "  - `tentative_price_usd`: *(int)* – The estimated price in USD  \n",
    "\n",
    "- Use `ChatPromptTemplate` to generate prompts for the LLM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e3fdfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"product_name\": \"Apple iPhone 16 Pro Max\",\n",
      "  \"product_details\": \"A premium smartphone with advanced camera features, a large display, and powerful performance.\",\n",
      "  \"tentative_price_usd\": 1199\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#Define the Pydantic model for product information\n",
    "class Product(BaseModel):\n",
    "    product_name: str = Field(..., description=\"Nmae of the product\")\n",
    "    product_details: str = Field(..., description=\"Details about the product\")\n",
    "    tentative_price_usd: int = Field(..., description=\"Tentative price in USD\")\n",
    "\n",
    "#Initialize the parser and get format instructions\n",
    "output_parser = PydanticOutputParser(pydantic_object=Product)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "#Build the prompt template \n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert assistant. Your task is to extract product information \"\n",
    "        \"from the user's text and format it as a JSON object according to the schema below. \"\n",
    "        \"Only output the JSON object. If the user's text does not contain enough information \"\n",
    "        \"for a field, you should try to infer it or use a sensible placeholder. \"\n",
    "        \"Prioritize accuracy based on the input. Ensure the output strictly follows the provided JSON schema.\"\n",
    "        \"\\n\\nSchema:\\n{format_instructions}\"\n",
    "    )),\n",
    "    (\"human\", \"{user_query}\")\n",
    "]).partial(format_instructions=output_parser.get_format_instructions())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Initialize the LLM and chain \n",
    "model = ChatGroq(model=\"gemma2-9b-it\",  temperature=0.7 )\n",
    "chain = prompt_template | model | output_parser\n",
    "\n",
    "#Straightforward invocation\n",
    "product: Product = chain.invoke({\n",
    "    \"user_query\": \"Tell me about the Apple iPhone 16 Pro Max.\"\n",
    "})\n",
    "\n",
    "\n",
    "print(product.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6013e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query 1: Tell me about the Apple iPhone 16 Pro Max.\n",
      "product_name='Apple iPhone 16 Pro Max' product_details='The Apple iPhone 16 Pro Max is a flagship smartphone expected to feature a large display, advanced camera system, and powerful processor.' tentative_price_usd=1199\n",
      "Successfully parsed Query 1:\n",
      "  Name: Apple iPhone 16 Pro Max\n",
      "  Details: The Apple iPhone 16 Pro Max is a flagship smartphone expected to feature a large display, advanced camera system, and powerful processor.\n",
      "  Price: $1199\n",
      "\n",
      "Processing Query 2: Tell me about Ipad Pro 12.9 inch.\n",
      "product_name='iPad Pro 12.9 inch' product_details='A premium tablet featuring a large, high-resolution display, powerful processor, and advanced features like a LiDAR scanner and M2 chip.' tentative_price_usd=1099\n",
      "Successfully parsed Query 2:\n",
      "  Name: iPad Pro 12.9 inch\n",
      "  Details: A premium tablet featuring a large, high-resolution display, powerful processor, and advanced features like a LiDAR scanner and M2 chip.\n",
      "  Price: $1099\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser # Good to have if direct parsing fails\n",
    "from langchain_openai import ChatOpenAI # Import ChatOpenAI\n",
    "\n",
    "# 1. Define your Pydantic model for the product\n",
    "class Product(BaseModel):\n",
    "    product_name: str = Field(description=\"The name of the product\")\n",
    "    product_details: str = Field(description=\"Detailed description of the product\")\n",
    "    tentative_price_usd: int = Field(description=\"The tentative price of the product in USD\")\n",
    "\n",
    "def create_product_assistant_chain(llm_instance):\n",
    "    \"\"\"\n",
    "    Creates a Langchain chain that takes a user query,\n",
    "    extracts product information, and returns a Pydantic Product object.\n",
    "    \"\"\"\n",
    "    # 2. Set up the PydanticOutputParser\n",
    "    parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "    # 3. Create the ChatPromptTemplate\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert assistant. Your task is to extract product information \"\n",
    "            \"from the user's text and format it as a JSON object according to the schema below. \"\n",
    "            \"Only output the JSON object. If the user's text does not contain enough information \"\n",
    "            \"for a field, you should try to infer it or use a sensible placeholder. \"\n",
    "            \"Prioritize accuracy based on the input. Ensure the output strictly follows the provided JSON schema.\"\n",
    "            \"\\n\\nSchema:\\n{format_instructions}\"\n",
    "        )),\n",
    "        (\"human\", \"{user_query}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt_template | llm_instance | parser\n",
    "    return chain\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Use ChatOpenAI as specified\n",
    "        llm = ChatGroq(model=\"gemma2-9b-it\",  temperature=0.7 )\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"ImportError: langchain_openai is not installed.\")\n",
    "        print(\"Please install it: pip install langchain-openai\")\n",
    "        exit()\n",
    "    except Exception as e: # Catch other potential errors during LLM instantiation\n",
    "        print(f\"Error instantiating ChatOpenAI: {e}\")\n",
    "        print(\"This could be due to a missing API key or other configuration issues.\")\n",
    "        exit()\n",
    "\n",
    "    product_chain = create_product_assistant_chain(llm)\n",
    "\n",
    "\n",
    "    # Example queries:\n",
    "    query1 = \"Tell me about the Apple iPhone 16 Pro Max.\"\n",
    "    query2 = \"Tell me about Ipad Pro 12.9 inch.\"\n",
    "\n",
    "\n",
    "    queries = {\n",
    "        \"Query 1\": query1,\n",
    "        \"Query 2\": query2,\n",
    "\n",
    "    }\n",
    "\n",
    "    for name, query_text in queries.items():\n",
    "        print(f\"\\nProcessing {name}: {query_text}\")\n",
    "        try:\n",
    "            # The input to the chain should match the variables in your prompt template\n",
    "            product_info = product_chain.invoke({\"user_query\": query_text})\n",
    "            print(product_info)\n",
    "            print(f\"Successfully parsed {name}:\")\n",
    "            print(f\"  Name: {product_info.product_name}\")\n",
    "            print(f\"  Details: {product_info.product_details}\")\n",
    "            print(f\"  Price: ${product_info.tentative_price_usd}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {name}: {e}\")\n",
    "            print(\"This might happen if the LLM output is not perfectly structured JSON for the Pydantic model.\")\n",
    "            print(\"You might want to inspect the raw output from the LLM or try adding StrOutputParser() before PydanticOutputParser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4dd958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ChatGroq(model='gemma2-9b-it', temperature=0.7)\n",
      "Make sure your GROQ_API_KEY environment variable is set if using Groq.\n",
      "\n",
      "Processing Query: Tell me about the Apple iPhone 16 Pro Max.\n",
      "\n",
      "--- Attempting to get RAW LLM String Output (should be JSON) ---\n",
      "Raw output string from LLM:\n",
      "```text\n",
      "```json\n",
      "{\n",
      "  \"product_name\": \"Apple iPhone 16 Pro Max\",\n",
      "  \"product_details\": \"The Apple iPhone 16 Pro Max is a flagship smartphone expected to be released in late 2023. It is anticipated to feature a larger display, upgraded camera system, and faster processor.\",\n",
      "  \"tentative_price_usd\": 1099\n",
      "}\n",
      "```\n",
      "```\n",
      "\n",
      "--- Attempting to parse into Pydantic Object ---\n",
      "Successfully parsed into Pydantic Product object:\n",
      "  Python Object Representation: product_name='Apple iPhone 16 Pro Max' product_details='The Apple iPhone 16 Pro Max is a flagship smartphone with advanced features and a premium design.' tentative_price_usd=1299\n",
      "  As JSON from Pydantic object: {\n",
      "  \"product_name\": \"Apple iPhone 16 Pro Max\",\n",
      "  \"product_details\": \"The Apple iPhone 16 Pro Max is a flagship smartphone with advanced features and a premium design.\",\n",
      "  \"tentative_price_usd\": 1299\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser # Import StrOutputParser\n",
    "from langchain_groq import ChatGroq # Assuming you're using ChatGroq as in your working example\n",
    "\n",
    "# 1. Define  Pydantic model for the product\n",
    "class Product(BaseModel):\n",
    "    product_name: str = Field(description=\"The name of the product\")\n",
    "    product_details: str = Field(description=\"Detailed description of the product\")\n",
    "    tentative_price_usd: int = Field(description=\"The tentative price of the product in USD\")\n",
    "\n",
    "# 2. Set up the PydanticOutputParser\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "# 3. Create the ChatPromptTemplate \n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You are an expert assistant. Your task is to extract product information \"\n",
    "        \"from the user's text and format it as a JSON object according to the schema below. \"\n",
    "        \"Only output the JSON object. If the user's text does not contain enough information \"\n",
    "        \"for a field, you should try to infer it or use a sensible placeholder. \"\n",
    "        \"Prioritize accuracy based on the input. Ensure the output strictly follows the provided JSON schema.\"\n",
    "        \"\\n\\nSchema:\\n{format_instructions}\"\n",
    "    )),\n",
    "    (\"human\", \"{user_query}\")\n",
    "]).partial(format_instructions=pydantic_parser.get_format_instructions())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        llm = ChatGroq(model=\"gemma2-9b-it\", temperature=0.7)\n",
    "        print(\"Using ChatGroq(model='gemma2-9b-it', temperature=0.7)\")\n",
    "        print(\"Make sure your GROQ_API_KEY environment variable is set if using Groq.\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"ImportError: langchain_groq is not installed.\")\n",
    "        print(\"Please install it: pip install langchain-groq\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error instantiating ChatGroq: {e}\")\n",
    "        print(\"This could be due to a missing API key or other configuration issues.\")\n",
    "        exit()\n",
    "\n",
    "    # Chain to get the RAW STRING output from LLM (intended to be JSON)\n",
    "    chain_for_raw_llm_output = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Original chain that parses into Pydantic object\n",
    "    chain_for_pydantic_object = prompt_template | llm | pydantic_parser\n",
    "\n",
    "\n",
    "    # query1\n",
    "    query1 = \"Tell me about the Apple iPhone 16 Pro Max.\"\n",
    "\n",
    "    print(f\"\\nProcessing Query: {query1}\")\n",
    "\n",
    "    # --- Get and print the raw LLM string output ---\n",
    "    print(\"\\n--- Attempting to get RAW LLM String Output (should be JSON) ---\")\n",
    "    try:\n",
    "        raw_output_string = chain_for_raw_llm_output.invoke({\"user_query\": query1})\n",
    "        print(\"Raw output string from LLM:\")\n",
    "        print(\"```text\") \n",
    "        print(raw_output_string)\n",
    "        print(\"```\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting raw LLM output: {e}\")\n",
    "\n",
    "    # --- Get and print the parsed Pydantic object  ---\n",
    "    print(\"\\n--- Attempting to parse into Pydantic Object ---\")\n",
    "    try:\n",
    "        product_info = chain_for_pydantic_object.invoke({\"user_query\": query1})\n",
    "        print(\"Successfully parsed into Pydantic Product object:\")\n",
    "        print(f\"  Python Object Representation: {product_info}\") # Pydantic's __str__/__repr__\n",
    "        print(f\"  As JSON from Pydantic object: {product_info.model_dump_json(indent=2)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing into Pydantic object: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AgenticAI)",
   "language": "python",
   "name": "agenticai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
